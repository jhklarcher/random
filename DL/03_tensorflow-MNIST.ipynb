{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-Old.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgtxEPd1XIegL/z6wzVhcD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bah6WSfhVJLI",
        "colab_type": "code",
        "outputId": "e2f6ebdf-ade6-4674-a1be-b43f083746a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMzV1E06VKxr",
        "colab_type": "code",
        "outputId": "38579a90-a102-4c28-b8b1-c965bdc3a808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
        "\n",
        "n_nodes_hl1 = 500\n",
        "n_nodes_hl2 = 500\n",
        "n_nodes_hl3 = 500\n",
        "\n",
        "n_classes = 10\n",
        "batch_size = 100\n",
        "\n",
        "x = tf.placeholder('float', [None, 784])\n",
        "y = tf.placeholder('float')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJJm4jI_VZAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_model(data):\n",
        "  hidden_1_layer = {'weights':tf.Variable(tf.random_normal([784, n_nodes_hl1])),\n",
        "                    'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
        "  hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
        "                    'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
        "  hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
        "                    'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
        "  output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
        "               'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
        "\n",
        "  l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases']) \n",
        "  l1 = tf.nn.relu(l1)\n",
        "\n",
        "  l2 = tf.add(tf.matmul(l1, hidden_2_layer['weights']), hidden_2_layer['biases']) \n",
        "  l2 = tf.nn.relu(l2)\n",
        "\n",
        "  l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']), hidden_3_layer['biases']) \n",
        "  l3 = tf.nn.relu(l3)\n",
        "\n",
        "  output = tf.matmul(l3, output_layer['weights']) + output_layer['biases']\n",
        "  \n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYZF47w_Vv__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_nn(x):\n",
        "  prediction = nn_model(x)\n",
        "  cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) ) \n",
        "  optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "\n",
        "  hm_epochs = 100\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.initialize_all_variables())\n",
        "\n",
        "    for epoch in range(hm_epochs):\n",
        "      epoch_loss = 0\n",
        "      for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "        epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "        _, c = sess.run([optimizer, cost], feed_dict = {x: epoch_x, y: epoch_y})\n",
        "        epoch_loss += c\n",
        "      print('Epoch', epoch, 'completed out of', hm_epochs, 'loos:', epoch_loss)\n",
        "\n",
        "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
        "    print('Accuracy:', accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czccoJOOWDcI",
        "colab_type": "code",
        "outputId": "d5ff29da-e293-4e81-ec05-27689a0f43ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_nn(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 completed out of 100 loos: 1773586.6261901855\n",
            "Epoch 1 completed out of 100 loos: 427738.7951374054\n",
            "Epoch 2 completed out of 100 loos: 227573.60903787613\n",
            "Epoch 3 completed out of 100 loos: 138629.70288691996\n",
            "Epoch 4 completed out of 100 loos: 83264.95793507993\n",
            "Epoch 5 completed out of 100 loos: 55392.99914804101\n",
            "Epoch 6 completed out of 100 loos: 36142.66924102232\n",
            "Epoch 7 completed out of 100 loos: 26131.58788002521\n",
            "Epoch 8 completed out of 100 loos: 25038.72776123573\n",
            "Epoch 9 completed out of 100 loos: 16766.13240388751\n",
            "Epoch 10 completed out of 100 loos: 16689.02553779024\n",
            "Epoch 11 completed out of 100 loos: 17008.15350478515\n",
            "Epoch 12 completed out of 100 loos: 16169.695689322947\n",
            "Epoch 13 completed out of 100 loos: 13595.719131245278\n",
            "Epoch 14 completed out of 100 loos: 13126.388913059694\n",
            "Epoch 15 completed out of 100 loos: 17768.002773879278\n",
            "Epoch 16 completed out of 100 loos: 11370.67162658988\n",
            "Epoch 17 completed out of 100 loos: 9335.424097557814\n",
            "Epoch 18 completed out of 100 loos: 10641.662844231003\n",
            "Epoch 19 completed out of 100 loos: 8916.405043778563\n",
            "Epoch 20 completed out of 100 loos: 7827.1430291980505\n",
            "Epoch 21 completed out of 100 loos: 9437.123466413468\n",
            "Epoch 22 completed out of 100 loos: 9494.605259659322\n",
            "Epoch 23 completed out of 100 loos: 10040.126832264064\n",
            "Epoch 24 completed out of 100 loos: 7123.134420402348\n",
            "Epoch 25 completed out of 100 loos: 8145.093268888591\n",
            "Epoch 26 completed out of 100 loos: 6411.014087061752\n",
            "Epoch 27 completed out of 100 loos: 7283.775791592896\n",
            "Epoch 28 completed out of 100 loos: 9631.815101411194\n",
            "Epoch 29 completed out of 100 loos: 7743.187387935817\n",
            "Epoch 30 completed out of 100 loos: 6028.317161306739\n",
            "Epoch 31 completed out of 100 loos: 5568.958434517495\n",
            "Epoch 32 completed out of 100 loos: 5849.1846750026925\n",
            "Epoch 33 completed out of 100 loos: 6797.1583931446075\n",
            "Epoch 34 completed out of 100 loos: 5119.113289952278\n",
            "Epoch 35 completed out of 100 loos: 5874.880672836676\n",
            "Epoch 36 completed out of 100 loos: 7260.3337919563055\n",
            "Epoch 37 completed out of 100 loos: 5672.511044293642\n",
            "Epoch 38 completed out of 100 loos: 5399.000730752945\n",
            "Epoch 39 completed out of 100 loos: 4948.496737219095\n",
            "Epoch 40 completed out of 100 loos: 3602.16118177741\n",
            "Epoch 41 completed out of 100 loos: 3562.985061788345\n",
            "Epoch 42 completed out of 100 loos: 5323.784626308059\n",
            "Epoch 43 completed out of 100 loos: 7191.4684507738075\n",
            "Epoch 44 completed out of 100 loos: 3379.573802679777\n",
            "Epoch 45 completed out of 100 loos: 4079.40947668206\n",
            "Epoch 46 completed out of 100 loos: 5110.898853257779\n",
            "Epoch 47 completed out of 100 loos: 4226.89591880294\n",
            "Epoch 48 completed out of 100 loos: 3884.5888744044305\n",
            "Epoch 49 completed out of 100 loos: 4024.1953389048576\n",
            "Epoch 50 completed out of 100 loos: 2841.377606883645\n",
            "Epoch 51 completed out of 100 loos: 4614.58044628799\n",
            "Epoch 52 completed out of 100 loos: 4055.839851822874\n",
            "Epoch 53 completed out of 100 loos: 3346.181932300329\n",
            "Epoch 54 completed out of 100 loos: 3844.04709216837\n",
            "Epoch 55 completed out of 100 loos: 4401.301574342928\n",
            "Epoch 56 completed out of 100 loos: 3597.427875904026\n",
            "Epoch 57 completed out of 100 loos: 3110.056591304019\n",
            "Epoch 58 completed out of 100 loos: 4529.975818395615\n",
            "Epoch 59 completed out of 100 loos: 3550.4139073450497\n",
            "Epoch 60 completed out of 100 loos: 2296.0110901892185\n",
            "Epoch 61 completed out of 100 loos: 4038.0022992789745\n",
            "Epoch 62 completed out of 100 loos: 4877.996466636658\n",
            "Epoch 63 completed out of 100 loos: 3137.153549078852\n",
            "Epoch 64 completed out of 100 loos: 2999.883476358056\n",
            "Epoch 65 completed out of 100 loos: 4041.766282439232\n",
            "Epoch 66 completed out of 100 loos: 3323.981121107936\n",
            "Epoch 67 completed out of 100 loos: 2572.094198167324\n",
            "Epoch 68 completed out of 100 loos: 3290.213473861012\n",
            "Epoch 69 completed out of 100 loos: 3021.173014163971\n",
            "Epoch 70 completed out of 100 loos: 2675.0588914752007\n",
            "Epoch 71 completed out of 100 loos: 3080.631651043892\n",
            "Epoch 72 completed out of 100 loos: 2139.058518052101\n",
            "Epoch 73 completed out of 100 loos: 2052.088819118418\n",
            "Epoch 74 completed out of 100 loos: 3128.709405425787\n",
            "Epoch 75 completed out of 100 loos: 3908.6676803827286\n",
            "Epoch 76 completed out of 100 loos: 3120.4663465321064\n",
            "Epoch 77 completed out of 100 loos: 2170.5724581338945\n",
            "Epoch 78 completed out of 100 loos: 2093.813310345411\n",
            "Epoch 79 completed out of 100 loos: 3091.0907110138487\n",
            "Epoch 80 completed out of 100 loos: 2557.4557980000973\n",
            "Epoch 81 completed out of 100 loos: 2496.1162742972374\n",
            "Epoch 82 completed out of 100 loos: 1674.7085935249925\n",
            "Epoch 83 completed out of 100 loos: 2766.012689113617\n",
            "Epoch 84 completed out of 100 loos: 1713.6691827178001\n",
            "Epoch 85 completed out of 100 loos: 2983.6016320014\n",
            "Epoch 86 completed out of 100 loos: 2575.365927517414\n",
            "Epoch 87 completed out of 100 loos: 3039.660589516163\n",
            "Epoch 88 completed out of 100 loos: 2010.2824284881353\n",
            "Epoch 89 completed out of 100 loos: 3385.2611250695772\n",
            "Epoch 90 completed out of 100 loos: 2204.6003372716905\n",
            "Epoch 91 completed out of 100 loos: 1185.0212204903364\n",
            "Epoch 92 completed out of 100 loos: 1410.9734689034522\n",
            "Epoch 93 completed out of 100 loos: 2197.4159840643406\n",
            "Epoch 94 completed out of 100 loos: 3115.4150463426486\n",
            "Epoch 95 completed out of 100 loos: 2613.1816588640213\n",
            "Epoch 96 completed out of 100 loos: 2110.2366863997304\n",
            "Epoch 97 completed out of 100 loos: 2245.165568649769\n",
            "Epoch 98 completed out of 100 loos: 1988.2992908966542\n",
            "Epoch 99 completed out of 100 loos: 2044.9414730376006\n",
            "Accuracy: 0.9765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-TNF47YZfOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}